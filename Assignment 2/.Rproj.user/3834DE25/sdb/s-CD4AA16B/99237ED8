{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Applied Bayesian Statistics - Assignment 2\"\nauthor: \"Benjamin Cole - s3412349\"\ndate: \"12 September 2018\"\noutput: html_document\n---\n\n### Data and Packages\n\n```{r, echo=T, message=F, warning=F, results='hide'}\n\npackages <- c(\"tidyverse\",\n              \"ggplot2\",\n              \"rmarkdown\",\n              \"knitr\",\n              \"kableExtra\",\n              \"purrr\",\n              \"scales\",\n              \"rjags\",\n              \"runjags\",\n              \"coda\",\n              \"readr\",\n              \"beepr\")\n\nlapply(packages, library, character.only=T)\n\nsource(\"DBDA2E-utilities.R\")\n\n# Data\nPropertyPrices <- read_csv(\"Assignment2PropertyPrices.csv\")\n\nPropertyPrices$SalePrice <- as.numeric(PropertyPrices$SalePrice)\n\n```\n\n# **Part A**\n\n### Model Diagram Parameters\n\n```{r, fig.width=10, fig.height=7, warning=F, message=F, echo=T}\n\nPropertyPrices %>% summarise(\"Mean Sale Price\" = mean(SalePrice),\n                             \"Sale Price Var\" = var(SalePrice),\n                             \"Sale Price SD\" = sd(SalePrice),\n                             \"Min Sale Price\" = min(SalePrice),\n                             \"Max Sale Price\" = max(SalePrice),\n                             \"n Observations\" = n()) %>% \n  gather(key=\"Measure\",\n         value=\"Value\") %>% \n  kable(align=\"lr\", \"html\",\n        format.args = list(trim=F,\n                           digits=1,\n                           nsmall=1,\n                           scientific=F,\n                           big.mark=\" \")) %>% \n  kable_styling(full_width=F,\n                bootstrap_options=)\n\n# Sale price hist\nggplot(PropertyPrices, aes(x=SalePrice)) +\n  geom_histogram(aes(fill=factor(PropertyPrices$PropertyType,\n                                    labels=c(\"House\", \"Unit\"))),\n                 col=\"white\",\n                 bins=40,\n                 alpha=2/3) +\n  scale_x_continuous(\"Sale Price (AUD)\",\n                     labels=dollar) +\n  scale_y_continuous(\"Number of Properties\",\n                     label=comma) + \n  scale_fill_manual(\"Property Type\",\n                    values=c(\"blue3\", \"cyan3\")) +\n  ggtitle(\"Sale Price Histogram\") +\n  theme_minimal()\n\n```\n\n`SalePrice` is right-skewed and not normally distributed. However, as \\(n=10,000\\), CLT can be assumed and that distribution of sampling means would be Gaussian. As such, the Bayesian model diagram is:\n\n![Model Diagram](Model Diagram Part A.png)\n\n### JAGS Data and Model blocks\n\n```{r, warning=F, message=F, echo=T}\n\nvectSalePrice <- PropertyPrices$SalePrice\nnTotal <- length(vectSalePrice)\n\ndataList <- list(\n  vectSalePrice = vectSalePrice,\n  nTotal = nTotal\n)\n\nvar(vectSalePrice)\n\n\nmodelString <- c(\"\nmodel {\n  # priors\n  mu ~ dnorm(609360.2, tau)\n  tau ~ dgamma(0.001, 1/(262475685684))\n\n  # likelihood\n  for (i in 1:nTotal) {\n    vectSalePrice[i] ~ dnorm(mu, tau)\n  }\n}\n\"\n)\n\n\nwriteLines(modelString, con=\"normJAGSmodel.txt\")\n\n```\n\n### Compile Model and run Markov Chains\n\n\n```{r, warning=F, message=F, echo=T, fig.width=10, fig.height=8}\n\njagsModel <- jags.model(file=\"normJAGSmodel.txt\",\n                        data=dataList,\n                        n.chains=5,\n                        n.adapt=150\n                        )\n\nupdate(jagsModel,\n       n.iter=500)\n\ncodaSamples <- coda.samples(jagsModel,\n                            variable.names=c(\"mu\"),\n                            n.iter=2500\n                            )\n\n# beep(2)\n\n# Display MCMC diagnostics\ndiagMCMC(codaObject=codaSamples,\n         parName=\"mu\")\n\n# Display the posterior distribution of mu\nplotPost(codaSamples[,\"mu\"],\n          main=\"mu\",\n          xlab=bquote(mu)\n         )\n\n```\n\n### Interpretation\n\n#### Chain Representativeness\n\nThe chains all seem to have settled about \\(\\bar{x}\\approx 610,000\\). The chains seem to mix well, with most values of each iteration being between \\(590,000\\) and \\(630,000\\). After the burn-in period, the chains can be seen in the smoothed density plot to overlap well. The shrink factor can also be observed to be very close to one after the burn-in period. The \\(95\\%\\) High Density Interval is \\((598981.1, 618939.5)\\), with a mode of \\(609 000\\).\n\n#### Chain Accuracy\n\nThe *Effective Sample Size* is the same length of the chain \\((ESS=12500)\\) and the *Monte Carlo standard error* is somewhat low compared to \\(\\bar{x}\\approx 610,000\\) at \\((MCSE\\approx46.2)\\). Considering the *Effective Sample Size* adn the *Monte Carlo standard error*, it can be suggested that the chains are accurate represenations of the posterior probability distribution.\n\n\n# **Part B**\n\n### Regression Model\n\nThe following expert knowledge has been provided for the predictor variables of the data set, which allows for prior distributions to be defined:\n\"\n* Area: Every m2 increase in land size increases the sales price by 90 AUD. This is a very strong expert knowledge.\n* Bedrooms: Every additional bedroom increases the sales price by 100,000AUD. This is a weak expert knowledge.\n* Bathrooms: There is no expert knowledge on the number of bathrooms.\n* CarParks: Every additional car space increases the sales price by 120,000AUD. This is a strong expert knowledge.\n* PropertyType: If the property is a unit, the sale price will be 150,000 AUD less than that of a house on the average. This is a very strong expert knowledge.\n\"\n\nThese prior distributions will be used in the multiple linear regression equation \\(\\mu=\\beta_0+\\beta_1X_1+\\beta_2X_2+\\beta_3X_3+\\beta_4X_4+\\beta_5X_5\\), which can be modelled as:\n\n![Generic Model Diagram](Model Diagram Part B.png)\n\nWith the distributions of predictors (denoted \\(j\\)) defined per predictor as:\n\n1. Area:\n$$\\beta_1 = j\\sim N\\left(\\mu=90, \\tau=\\left(\\frac{1}{\\sigma_y^2}\\right)\\times0.01\\right)$$\n\n2. Bedrooms:\n$$\\beta_2 =j\\sim N\\left(\\mu=100\\ 000,\\tau=\\left(\\frac{1}{\\sigma_y^2} \\right)\\times0.75 \\right)$$\n\n3. Bathrooms\n$$\\beta_3 =j\\sim N\\left(\\mu=609\\ 360.2,\\tau=\\left(\\frac{1}{\\sigma_y^2}\\right) \\times100 \\right)$$\n```{r, collapse=T}\n# mean of SalePrice\nmean(PropertyPrices$SalePrice) %>% format(big.mark=\" \")\n```\n\n4. CarParks:\n$$\\beta_4=j\\sim N\\left(\\mu=120\\,000,\\tau=\\left(\\frac{1}{\\sigma_y^2}\\right) \\times0.1\\right)$$\n\n5. PropertyType:\n$$\\beta_5 = j\\sim N\\left(\\mu=150\\ 000, \\tau=\\left(\\frac{1}{\\sigma_y^2}\\right)\\times 0.01\\right)$$\n\n#### Data and Model Block\n\n```{r}\n\n  modelString = \"\n  # Standardize the data:\n  data {\n    ym <- mean(y)\n    ysd <- sd(y)\n    for ( i in 1:Ntotal ) {\n      zy[i] <- ( y[i] - ym ) / ysd\n    }\n    for ( j in 1:Nx ) {\n      xm[j]  <- mean(x[,j])\n      xsd[j] <-   sd(x[,j])\n      for ( i in 1:Ntotal ) {\n        zx[i,j] <- ( x[i,j] - xm[j] ) / xsd[j]\n      }\n    }\n\n    # Prior mus\n    mu0 <- ym # Set to overall mean a priori based on the interpretation of constant term in regression\n    mu[1] <- 90 # Area\n    mu[2] <- 100000 # Bedrooms\n    mu[3] <- 609360.2 # Bathrooms, muY\n    mu[4] <- 120000 # CarParks\n    mu[5] <- 0.5 # PropertyType\n\n    # Prior taus   \n    Var0 <- (1/(ysd^2))\n    Var[1] <- ((ysd^2)*0.01) # Area\n    Var[2] <- ((ysd^2)*0.75) # Bedrooms\n    Var[3] <- ((ysd^2)*100) # Bathrooms\n    Var[4] <- ((ysd^2)*0.1) # CarParks\n    Var[5] <- ((ysd^2)*0.01) # PropertyType\n\n    # Standardising mus\n    muZ[1:Nx] <-  mu[1:Nx] * xsd[1:Nx] / ysd \n\n    muZ0 <- (mu0 + sum( mu[1:Nx] * xm[1:Nx] / xsd[1:Nx] )*ysd - ym) / ysd \n\n    # Standardising taus\n    VarZ[1:Nx] <- Var[1:Nx] * ( xsd[1:Nx]/ ysd )^2\n    VarZ0 <- Var0 / (ysd^2)\n\n  }\n  # Specify the model for standardized data:\n  model {\n    for ( i in 1:Ntotal ) {\n      zy[i] ~ dt( zbeta0 + sum( zbeta[1:Nx] * zx[i,1:Nx] ) , 1/zsigma^2 , nu )\n    }\n\n    # Priors vague on standardized scale:\n    zbeta0 ~ dnorm( muZ0 , 1/VarZ0 )  \n    for ( j in 1:Nx ) {\n      zbeta[j] ~ dnorm( muZ[j] , 1/VarZ[j] )\n    }\n    zsigma ~ dgamma(0.01,0.01)#dunif( 1.0E-5 , 1.0E+1 )\n    nu ~ dexp(1/30.0)\n\n    # Transform to original scale:\n    beta[1:Nx] <- ( zbeta[1:Nx] / xsd[1:Nx] )*ysd\n    beta0 <- zbeta0*ysd  + ym - sum( zbeta[1:Nx] * xm[1:Nx] / xsd[1:Nx] )*ysd\n    sigma <- zsigma*ysd\n\n    # Compute predictions at every step of the MCMC\n    # pred <- beta0 + beta[1] * xPred[1] + beta[2] * xPred[2] + beta[3] * xPred[3] + beta[4] * xPred[4] \n    #         + beta[5] * xPred[5] + beta[6] * xPred[6] + beta[7] * xPred[7] \n\n  }\n  \"\n\n```\n\n\n### Standardising the Data\n\nTo reduce the autocorrelation of the regression model parameters, particularly \\(\\beta_0\\) & \\(\\beta_1\\), the data needs to be standardised as follows: \n\n$$z_{\\hat{y}}=\\zeta_0 SD_y +M_y -SD_y \\left(\\sum_{j=1} \\zeta_j \\frac{M_{x_{j}}}{SD_{x_{j}}} + \\sum_j \\left(\\zeta{_j} \\frac{SD_y}{SD_{x_{j}}}\\right) \\right)$$\n\nThe model block above uses this method to standardise the data for \\(\\beta_0\\) and each \\(\\beta_j\\) predictor.\n\n\n```{r}\n\nparameterNames = varnames(mcmcCoda)\n\nfor ( parName in parameterNames ) {\n  diagMCMC( codaObject=mcmcCoda , parName=parName , \n            saveName=fileNameRoot , saveType=graphFileType, \n            )\n}\n\n```\n\n\n```{r}\nplotMCMC( mcmcCoda , data=myData , xName=xName , yName=yName , \n          pairsPlot=TRUE , showCurve=TRUE ,\n          saveName=fileNameRoot , saveType=graphFileType )\n\n```\n\n",
    "created" : 1536731954673.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1830165998",
    "id" : "99237ED8",
    "lastKnownWriteTime" : 1537955265,
    "last_content_update" : 1537955265691,
    "path" : "~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Assignment_2.Rmd",
    "project_path" : "Assignment_2.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}