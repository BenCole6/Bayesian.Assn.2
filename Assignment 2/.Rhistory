writeLines( modelString , con="TEMPmodel.txt" )
#-----------------------------------------------------------------------------
# INTIALIZE THE CHAINS.
# Let JAGS do it...
# Must standardize data first...
#   lmInfo = lm( zy ~ zx )
#   initsList = list(
#     beta0 = lmInfo$coef[1] ,
#     beta = lmInfo$coef[-1] ,
#     sigma = sqrt(mean(lmInfo$resid^2)) ,
#     nu = 5
#   )
#-----------------------------------------------------------------------------
# RUN THE CHAINS
parameters = c( "beta0" ,  "beta" ,  "sigma",
"zbeta0" , "zbeta" , "zsigma", "nu" , "pred" )
adaptSteps = 500  # Number of steps to "tune" the samplers
burnInSteps = 1000
runJagsOut <- run.jags( method=runjagsMethod ,
model="TEMPmodel.txt" ,
monitor=parameters ,
data=dataList ,
#inits=initsList ,
n.chains=nChains ,
adapt=adaptSteps ,
burnin=burnInSteps ,
sample=ceiling(numSavedSteps/nChains) ,
thin=thinSteps ,
summarise=FALSE ,
plots=FALSE )
codaSamples = as.mcmc.list( runJagsOut )
# resulting codaSamples object has these indices:
#   codaSamples[[ chainIdx ]][ stepIdx , paramIdx ]
# Added by Demirhan
# if ( !any(is.null(xPred)) ) {
#   for ( i in 1:nChains){
#     pred = codaSamples[[i]][,"beta0"]
#     for ( pName in colnames(xPred) ) {
#       pred = pred + codaSamples[[i]][,pName]*as.numeric(xPred[pName])
#     }
#     codaSamples[[i]]  =cbind(codaSamples[[i]] , as.data.frame(as.matrix(pred)) )
#   }
#   codaSamples = as.mcmc.list( codaSamples )
#
# }
if ( !is.null(saveName) ) {
save( codaSamples , file=paste(saveName,"Mcmc.Rdata",sep="") )
}
return( codaSamples )
}
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2.R', echo=TRUE)
mcmcCoda = genMCMC( data=myData , xName=xName , yName=yName,
numSavedSteps = numSavedSteps , thinSteps=thinSteps ,
saveName=fileNameRoot)
mcmcCoda = genMCMC( data=myData , xName=xName , yName=yName,
numSavedSteps = numSavedSteps , thinSteps=thinSteps ,
saveName=fileNameRoot)
genMCMC = function( data , xName="x" , yName="y" ,
numSavedSteps=numSavedSteps , thinSteps=thinSteps , saveName=NULL  ,
runjagsMethod=runjagsMethodDefault ,
nChains=nChainsDefault) {
require(runjags)
#-----------------------------------------------------------------------------
# THE DATA.
y = data[,yName]
x = as.matrix(data[,xName],ncol=length(xName))
# Do some checking that data make sense:
if ( any( !is.finite(y) ) ) { stop("All y values must be finite.") }
if ( any( !is.finite(x) ) ) { stop("All x values must be finite.") }
cat("\nCORRELATION MATRIX OF PREDICTORS:\n ")
show( round(cor(x),3) )
cat("\n")
flush.console()
# Specify the data in a list, for later shipment to JAGS:
dataList = list(
x = x ,
y = y ,
Nx = dim(x)[2] ,
Ntotal = dim(x)[1]
)
#-----------------------------------------------------------------------------
# THE MODEL.
modelString = "
# Standardize the data:
data {
ym <- mean(y)
ysd <- sd(y)
for ( i in 1:Ntotal ) {
zy[i] <- ( y[i] - ym ) / ysd
}
for ( j in 1:Nx ) {
xm[j]  <- mean(x[,j])
xsd[j] <-   sd(x[,j])
for ( i in 1:Ntotal ) {
zx[i,j] <- ( x[i,j] - xm[j] ) / xsd[j]
}
}
# Specify the priors for original beta parameters
# Prior locations to reflect the expert information
mu0 <- ym # Set to overall mean a priori based on the interpretation of constant term in regression
mu[1] <- 90 # Area
mu[2] <- 100000 # Bedrooms
mu[3] <- 609360.2 # Bathrooms, muY
mu[4] <- 120000 # CarParks
# mu[5] <- 0.5 # PropertyType
# Prior variances to reflect the expert information
Var0 <- 1 # Set simply to 1
Var[1] <- (ysd^2)*0.01 # Area
Var[2] <- (ysd^2)*0.75 # Bedrooms
Var[3] <- (ysd^2)*100 # Bathrooms
Var[4] <- (ysd^2)*0.1 # CarParks
Var[5] <- (ysd^2)*0.1 # PropertyType
# Compute corresponding prior means and variances for the standardised parameters
muZ[1:nX] <-  mu[1:nX] * xsd[1:nX] / ysd
muZ0 <- (mu0 + sum( mu[1:nX] * xm[1:nX] / xsd[1:nX] )*ysd - ym) / ysd
# Compute corresponding prior variances and variances for the standardised parameters
VarZ[1:nX] <- Var[1:nX] * ( xsd[1:nX]/ ysd )^2
VarZ0 <- Var0 / (ysd^2)
}
# Specify the model for standardized data:
model {
for ( i in 1:Ntotal ) {
zy[i] ~ dt( zbeta0 + sum( zbeta[1:Nx] * zx[i,1:Nx] ) , 1/zsigma^2 , nu )
}
# Priors vague on standardized scale:
zbeta0 ~ dnorm( muZ0 , 1/VarZ0 )
for ( j in 1:Nx ) {
zbeta[j] ~ dnorm( muZ[j] , 1/VarZ[j] )
}
zsigma ~ dgamma(0.01,0.01)#dunif( 1.0E-5 , 1.0E+1 )
nu ~ dexp(1/30.0)
# Transform to original scale:
beta[1:Nx] <- ( zbeta[1:Nx] / xsd[1:Nx] )*ysd
beta0 <- zbeta0*ysd  + ym - sum( zbeta[1:Nx] * xm[1:Nx] / xsd[1:Nx] )*ysd
sigma <- zsigma*ysd
# Compute predictions at every step of the MCMC
pred <- beta0 + beta[1] * xPred[1] + beta[2] * xPred[2] + beta[3] * xPred[3] + beta[4] * xPred[4]
+ beta[5] * xPred[5] + beta[6] * xPred[6] + beta[7] * xPred[7]
}
" # close quote for modelString
# Write out modelString to a text file
writeLines( modelString , con="TEMPmodel.txt" )
#-----------------------------------------------------------------------------
# INTIALIZE THE CHAINS.
# Let JAGS do it...
# Must standardize data first...
#   lmInfo = lm( zy ~ zx )
#   initsList = list(
#     beta0 = lmInfo$coef[1] ,
#     beta = lmInfo$coef[-1] ,
#     sigma = sqrt(mean(lmInfo$resid^2)) ,
#     nu = 5
#   )
#-----------------------------------------------------------------------------
# RUN THE CHAINS
parameters = c( "beta0" ,  "beta" ,  "sigma",
"zbeta0" , "zbeta" , "zsigma", "nu" , "pred" )
adaptSteps = 500  # Number of steps to "tune" the samplers
burnInSteps = 1000
runJagsOut <- run.jags( method=runjagsMethod ,
model="TEMPmodel.txt" ,
monitor=parameters ,
data=dataList ,
#inits=initsList ,
n.chains=nChains ,
adapt=adaptSteps ,
burnin=burnInSteps ,
sample=ceiling(numSavedSteps/nChains) ,
thin=thinSteps ,
summarise=FALSE ,
plots=FALSE )
codaSamples = as.mcmc.list( runJagsOut )
if ( !is.null(saveName) ) {
save( codaSamples , file=paste(saveName,"Mcmc.Rdata",sep="") )
}
return( codaSamples )
}
mcmcCoda = genMCMC( data=myData , xName=xName , yName=yName,
numSavedSteps = numSavedSteps , thinSteps=thinSteps ,
saveName=fileNameRoot)
genMCMC = function( data , xName="x" , yName="y" ,
numSavedSteps=10000 , thinSteps=1 , saveName=NULL  ,
runjagsMethod=runjagsMethodDefault ,
nChains=nChainsDefault) {
require(runjags)
#-----------------------------------------------------------------------------
# THE DATA.
y = data[,yName]
x = as.matrix(data[,xName],ncol=length(xName))
# Do some checking that data make sense:
if ( any( !is.finite(y) ) ) { stop("All y values must be finite.") }
if ( any( !is.finite(x) ) ) { stop("All x values must be finite.") }
cat("\nCORRELATION MATRIX OF PREDICTORS:\n ")
show( round(cor(x),3) )
cat("\n")
flush.console()
# Specify the data in a list, for later shipment to JAGS:
dataList = list(
x = x ,
y = y ,
Nx = dim(x)[2] ,
Ntotal = dim(x)[1]
)
#-----------------------------------------------------------------------------
# THE MODEL.
modelString = "
# Standardize the data:
data {
ym <- mean(y)
ysd <- sd(y)
for ( i in 1:Ntotal ) {
zy[i] <- ( y[i] - ym ) / ysd
}
for ( j in 1:Nx ) {
xm[j]  <- mean(x[,j])
xsd[j] <-   sd(x[,j])
for ( i in 1:Ntotal ) {
zx[i,j] <- ( x[i,j] - xm[j] ) / xsd[j]
}
}
# Specify the priors for original beta parameters
# Prior locations to reflect the expert information
mu0 <- ym # Set to overall mean a priori based on the interpretation of constant term in regression
mu[1] <- 90 # Area
mu[2] <- 100000 # Bedrooms
mu[3] <- 609360.2 # Bathrooms, muY
mu[4] <- 120000 # CarParks
# mu[5] <- 0.5 # PropertyType
# Prior variances to reflect the expert information
Var0 <- 1 # Set simply to 1
Var[1] <- (ysd^2)*0.01 # Area
Var[2] <- (ysd^2)*0.75 # Bedrooms
Var[3] <- (ysd^2)*100 # Bathrooms
Var[4] <- (ysd^2)*0.1 # CarParks
Var[5] <- (ysd^2)*0.1 # PropertyType
# Compute corresponding prior means and variances for the standardised parameters
muZ[1:nX] <-  mu[1:nX] * xsd[1:nX] / ysd
muZ0 <- (mu0 + sum( mu[1:nX] * xm[1:nX] / xsd[1:nX] )*ysd - ym) / ysd
# Compute corresponding prior variances and variances for the standardised parameters
VarZ[1:nX] <- Var[1:nX] * ( xsd[1:nX]/ ysd )^2
VarZ0 <- Var0 / (ysd^2)
}
# Specify the model for standardized data:
model {
for ( i in 1:Ntotal ) {
zy[i] ~ dt( zbeta0 + sum( zbeta[1:Nx] * zx[i,1:Nx] ) , 1/zsigma^2 , nu )
}
# Priors vague on standardized scale:
zbeta0 ~ dnorm( muZ0 , 1/VarZ0 )
for ( j in 1:Nx ) {
zbeta[j] ~ dnorm( muZ[j] , 1/VarZ[j] )
}
zsigma ~ dgamma(0.01,0.01)#dunif( 1.0E-5 , 1.0E+1 )
nu ~ dexp(1/30.0)
# Transform to original scale:
beta[1:Nx] <- ( zbeta[1:Nx] / xsd[1:Nx] )*ysd
beta0 <- zbeta0*ysd  + ym - sum( zbeta[1:Nx] * xm[1:Nx] / xsd[1:Nx] )*ysd
sigma <- zsigma*ysd
# Compute predictions at every step of the MCMC
pred <- beta0 + beta[1] * xPred[1] + beta[2] * xPred[2] + beta[3] * xPred[3] + beta[4] * xPred[4]
+ beta[5] * xPred[5] + beta[6] * xPred[6] + beta[7] * xPred[7]
}
" # close quote for modelString
# Write out modelString to a text file
writeLines( modelString , con="TEMPmodel.txt" )
#-----------------------------------------------------------------------------
# INTIALIZE THE CHAINS.
# Let JAGS do it...
# Must standardize data first...
#   lmInfo = lm( zy ~ zx )
#   initsList = list(
#     beta0 = lmInfo$coef[1] ,
#     beta = lmInfo$coef[-1] ,
#     sigma = sqrt(mean(lmInfo$resid^2)) ,
#     nu = 5
#   )
#-----------------------------------------------------------------------------
# RUN THE CHAINS
parameters = c( "beta0" ,  "beta" ,  "sigma",
"zbeta0" , "zbeta" , "zsigma", "nu" , "pred" )
adaptSteps = 500  # Number of steps to "tune" the samplers
burnInSteps = 1000
runJagsOut <- run.jags( method=runjagsMethod ,
model="TEMPmodel.txt" ,
monitor=parameters ,
data=dataList ,
#inits=initsList ,
n.chains=nChains ,
adapt=adaptSteps ,
burnin=burnInSteps ,
sample=ceiling(numSavedSteps/nChains) ,
thin=thinSteps ,
summarise=FALSE ,
plots=FALSE )
codaSamples = as.mcmc.list( runJagsOut )
if ( !is.null(saveName) ) {
save( codaSamples , file=paste(saveName,"Mcmc.Rdata",sep="") )
}
return( codaSamples )
}
mcmcCoda = genMCMC( data=myData , xName=xName , yName=yName,
numSavedSteps = numSavedSteps , thinSteps=thinSteps ,
saveName=fileNameRoot)
graphFileType = "eps"
genMCMC = function( data , xName="x" , yName="y" ,
numSavedSteps=numSavedSteps , thinSteps=thinSteps , saveName=NULL  ,
runjagsMethod=runjagsMethodDefault ,
nChains=nChainsDefault) {
require(runjags)
#-----------------------------------------------------------------------------
# THE DATA.
y = data[,yName]
x = as.matrix(data[,xName],ncol=length(xName))
# Do some checking that data make sense:
if ( any( !is.finite(y) ) ) { stop("All y values must be finite.") }
if ( any( !is.finite(x) ) ) { stop("All x values must be finite.") }
cat("\nCORRELATION MATRIX OF PREDICTORS:\n ")
show( round(cor(x),3) )
cat("\n")
flush.console()
# Specify the data in a list, for later shipment to JAGS:
dataList = list(
x = x ,
y = y ,
Nx = dim(x)[2] ,
Ntotal = dim(x)[1]
)
#-----------------------------------------------------------------------------
# THE MODEL.
modelString = "
# Standardize the data:
data {
ym <- mean(y)
ysd <- sd(y)
for ( i in 1:Ntotal ) {
zy[i] <- ( y[i] - ym ) / ysd
}
for ( j in 1:Nx ) {
xm[j]  <- mean(x[,j])
xsd[j] <-   sd(x[,j])
for ( i in 1:Ntotal ) {
zx[i,j] <- ( x[i,j] - xm[j] ) / xsd[j]
}
}
# Specify the priors for original beta parameters
# Prior locations to reflect the expert information
mu0 <- ym # Set to overall mean a priori based on the interpretation of constant term in regression
mu[1] <- 90 # Area
mu[2] <- 100000 # Bedrooms
mu[3] <- 609360.2 # Bathrooms, muY
mu[4] <- 120000 # CarParks
# mu[5] <- 0.5 # PropertyType
# Prior variances to reflect the expert information
Var0 <- 1 # Set simply to 1
Var[1] <- (ysd^2)*0.01 # Area
Var[2] <- (ysd^2)*0.75 # Bedrooms
Var[3] <- (ysd^2)*100 # Bathrooms
Var[4] <- (ysd^2)*0.1 # CarParks
Var[5] <- (ysd^2)*0.1 # PropertyType
# Compute corresponding prior means and variances for the standardised parameters
muZ[1:nX] <-  mu[1:nX] * xsd[1:nX] / ysd
muZ0 <- (mu0 + sum( mu[1:nX] * xm[1:nX] / xsd[1:nX] )*ysd - ym) / ysd
# Compute corresponding prior variances and variances for the standardised parameters
VarZ[1:nX] <- Var[1:nX] * ( xsd[1:nX]/ ysd )^2
VarZ0 <- Var0 / (ysd^2)
}
# Specify the model for standardized data:
model {
for ( i in 1:Ntotal ) {
zy[i] ~ dt( zbeta0 + sum( zbeta[1:Nx] * zx[i,1:Nx] ) , 1/zsigma^2 , nu )
}
# Priors vague on standardized scale:
zbeta0 ~ dnorm( muZ0 , 1/VarZ0 )
for ( j in 1:Nx ) {
zbeta[j] ~ dnorm( muZ[j] , 1/VarZ[j] )
}
zsigma ~ dgamma(0.01,0.01)#dunif( 1.0E-5 , 1.0E+1 )
nu ~ dexp(1/30.0)
# Transform to original scale:
beta[1:Nx] <- ( zbeta[1:Nx] / xsd[1:Nx] )*ysd
beta0 <- zbeta0*ysd  + ym - sum( zbeta[1:Nx] * xm[1:Nx] / xsd[1:Nx] )*ysd
sigma <- zsigma*ysd
# Compute predictions at every step of the MCMC
pred <- beta0 + beta[1] * xPred[1] + beta[2] * xPred[2] + beta[3] * xPred[3] + beta[4] * xPred[4]
+ beta[5] * xPred[5] + beta[6] * xPred[6] + beta[7] * xPred[7]
}
" # close quote for modelString
# Write out modelString to a text file
writeLines( modelString , con="TEMPmodel.txt" )
#-----------------------------------------------------------------------------
# INTIALIZE THE CHAINS.
# Let JAGS do it...
# Must standardize data first...
#   lmInfo = lm( zy ~ zx )
#   initsList = list(
#     beta0 = lmInfo$coef[1] ,
#     beta = lmInfo$coef[-1] ,
#     sigma = sqrt(mean(lmInfo$resid^2)) ,
#     nu = 5
#   )
#-----------------------------------------------------------------------------
# RUN THE CHAINS
parameters = c( "beta0" ,  "beta" ,  "sigma",
"zbeta0" , "zbeta" , "zsigma", "nu" , "pred" )
adaptSteps = 500  # Number of steps to "tune" the samplers
burnInSteps = 1000
runJagsOut <- run.jags( method=runjagsMethod ,
model="TEMPmodel.txt" ,
monitor=parameters ,
data=dataList ,
#inits=initsList ,
n.chains=nChains ,
adapt=adaptSteps ,
burnin=burnInSteps ,
sample=ceiling(numSavedSteps/nChains) ,
thin=thinSteps ,
summarise=FALSE ,
plots=FALSE )
codaSamples = as.mcmc.list( runJagsOut )
if ( !is.null(saveName) ) {
save( codaSamples , file=paste(saveName,"Mcmc.Rdata",sep="") )
}
return( codaSamples )
}
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2-Run.R', echo=TRUE)
parameterNames = varnames(mcmcCoda) # get all parameter names
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2.R', echo=TRUE)
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2-Run.R', echo=TRUE)
# Var[5] <- (ysd^2)*0.1 # PropertyType
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2.R', echo=TRUE)
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2-Run.R', echo=TRUE)
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2.R', echo=TRUE)
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2-Run.R', echo=TRUE)
results.jags("C:/Users/benco.DESKTOP-K1JS793/AppData/Local/Temp/RtmpK6QSkA/runjagsfiles16185f22587",
recover.chains=TRUE)
results.jags("C:/Users/benco.DESKTOP-K1JS793/AppData/Local/Temp/RtmpK6QSkA/runjagsfiles16185f22587", recover.chains=TRUE)
source("Jags-Ymet-XmetMulti-Mrobust-Assn2.R")
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2-Run.R', echo=TRUE)
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2.R', echo=TRUE)
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2-Run.R', echo=TRUE)
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2.R', echo=TRUE)
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2-Run.R', echo=TRUE)
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2.R', echo=TRUE)
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2-Run.R', echo=TRUE)
ysd^2
sd(PropertyPrices$SalePrice)
sd(PropertyPrices$SalePrice)^2
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2.R', echo=TRUE)
beep(2)
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2-Run.R', echo=TRUE)
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2.R', echo=TRUE)
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2-Run.R', echo=TRUE)
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2.R', echo=TRUE)
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2-Run.R', echo=TRUE)
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2-Run.R', echo=TRUE)
diagMCMC( codaObject=mcmcCoda , parName=parName ,
saveName=fileNameRoot , saveType=graphFileType )
for ( parName in parameterNames ) {
diagMCMC( codaObject=mcmcCoda , parName=parName ,
saveName=fileNameRoot , saveType=graphFileType )
}
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2.R', echo=TRUE)
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2.R', echo=TRUE)
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2-Run.R', echo=TRUE)
plotMCMC( mcmcCoda , data=myData , xName=xName , yName=yName ,
pairsPlot=TRUE , showCurve=TRUE ,
saveName=fileNameRoot , saveType=graphFileType )
for ( parName in parameterNames ) {
diagMCMC( codaObject=mcmcCoda , parName=parName ,
saveName=fileNameRoot , saveType=graphFileType )
}
for ( parName in parameterNames ) {
diagMCMC( codaObject=mcmcCoda , parName=parName ,
saveName=fileNameRoot , saveType=graphFileType )
}
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2.R', echo=TRUE)
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2-Run.R', echo=TRUE)
for ( parName in parameterNames ) {
diagMCMC( codaObject=mcmcCoda , parName=parName ,
saveName=fileNameRoot , saveType=graphFileType )
}
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2.R', echo=TRUE)
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2-Run.R', echo=TRUE)
for ( parName in parameterNames ) {
diagMCMC( codaObject=mcmcCoda , parName=parName ,
saveName=fileNameRoot , saveType=graphFileType )
}
plotMCMC( mcmcCoda , data=myData , xName=xName , yName=yName ,
pairsPlot=TRUE , showCurve=TRUE ,
saveName=fileNameRoot , saveType=graphFileType )
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2-Run.R', echo=TRUE)
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2.R', echo=TRUE)
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2-Run.R', echo=TRUE)
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2.R', echo=TRUE)
source('~/RMIT/2018 RMIT SEM 2/Applied Bayesian Statistics/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2-Run.R', echo=TRUE)
for ( parName in parameterNames ) {
diagMCMC( codaObject=mcmcCoda , parName=parName ,
saveName=fileNameRoot , saveType=graphFileType )
}
for ( parName in parameterNames ) {
diagMCMC( codaObject=mcmcCoda , parName=parName ,
saveName=fileNameRoot , saveType=graphFileType )
}
mcmcCoda
parameterNames
diagMCMC( codaObject=mcmcCoda , parName=parName ,
saveName=fileNameRoot , saveType=graphFileType )
for ( parName in parameterNames ) {
diagMCMC( codaObject=mcmcCoda , parName=parName ,
saveName=fileNameRoot , saveType=graphFileType )
}
source('~/GitHub/Bayesian.Assn.2/Assignment 2/Jags-Ymet-XmetMulti-Mrobust-Assn2-Run.R', echo=TRUE)
